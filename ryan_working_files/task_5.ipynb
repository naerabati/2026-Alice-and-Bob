{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Quantum error correction inspired by classical codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Task 5.1 - Explore QEC codes inspired by classical codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TODO, 70pts]:\n",
    "\n",
    "Classical error correcting codes provide a natural and powerful pathway to constructing quantum codes by directly translating classical parity checks into quantum stabilizer measurements. In particular, any linear classical code can be mapped to a quantum code that detects and corrects **bit flip (X) errors** by promoting each classical parity check into a multi-qubit ( Z )-type stabilizer. In this construction, classical codewords become logical quantum states, and the syndrome extraction process is identical in spirit to classical decoding. This approach is especially well suited for hardware with **strong noise bias**, where one error channel dominates. In our case, biased cat qubits exponentially suppress phase flip errors, leaving bit flips as the primary failure mode. As a result, we can focus entirely on X-error correction, allowing us to use a much wider and more efficient family of classical codes than would be possible for fully general quantum noise.\n",
    "\n",
    "The final and core challenge is to choose any classical error correcting code (or family of codes), translate it into its quantum counterpart, and benchmark it against the repetition code that you already implemented. You will simulate the resulting quantum code in **Stim**, extract syndromes, perform decoding, and compare key performance metrics such as logical error rate versus number of physical qubits at a fixed physical error rate, encoding efficiency ( k/n ), the effective distance of the code and required hardware connectivity (i.e. what two-qubit gates are needed). This exploration will show how classical coding theory can be directly leveraged to design quantum codes that outperform simple repetition strategies when the noise is strongly biased.\n",
    "\n",
    "*Optionally*, only if time permits, you may wish to demonstrate a universal, fault-tolerant set of logical gates for your code, starting with the Clifford group and extending to non-Clifford gates.\n",
    "\n",
    "\n",
    "Please refer to `./2-classical-to-quantum-codes.ipynb` for a step-by-step introduction to translating a classical code into a quantum bit-flipâ€“correcting code, along with a curated (but not exhaustive) list of classical code families to use as inspiration. You should consider this notebook required reading for the core task in this challenge.\n",
    "\n",
    "This is an open-ended challenge, judged by the criteria specified in the `README.md` doc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building concatenated Hamming circuit...\n",
      "Circuit has 49 data qubits and 21 stabilizers\n",
      "\n",
      "Circuit preview (first 20 lines):\n",
      "R 0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 1 3 5 7 9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41\n",
      "TICK\n",
      "X_ERROR(0.05) 0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96\n",
      "TICK\n",
      "CX 0 1 4 1 8 1 12 1 2 3 4 3 10 3 12 3 6 5 8 5 10 5 12 5 14 7 18 7 22 7 26 7 16 9 18 9 24 9 26 9 20 11 22 11 24 11 26 11 28 13 32 13 36 13 40 13 30 15 32 15 38 15 40 15 34 17 36 17 38 17 40 17 42 19 46 19 50 19 54 19 44 21 46 21 52 21 54 21 48 23 50 23 52 23 54 23 56 25 60 25 64 25 68 25 58 27 60 27 66 27 68 27 62 29 64 29 66 29 68 29 70 31 74 31 78 31 82 31 72 33 74 33 80 33 82 33 76 35 78 35 80 35 82 35 84 37 88 37 92 37 96 37 86 39 88 39 94 39 96 39 90 41 92 41 94 41 96 41\n",
      "TICK\n",
      "MR 1 3 5 7 9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41\n",
      "DETECTOR rec[-21]\n",
      "DETECTOR rec[-20]\n",
      "DETECTOR rec[-19]\n",
      "DETECTOR rec[-18]\n",
      "DETECTOR rec[-17]\n",
      "DETECTOR rec[-16]\n",
      "DETECTOR rec[-15]\n",
      "DETECTOR rec[-14]\n",
      "DETECTOR rec[-13]\n",
      "DETECTOR rec[-12]\n",
      "DETECTOR rec[-11]\n",
      "DETECTOR rec[-10]\n",
      "DETECTOR rec[-9]\n",
      "\n",
      "Running simulation...\n",
      "\n",
      "Number of unique measurement outcomes: 3108\n",
      "Most common outcomes:\n",
      "  1. syndrome=0000000000... data=0000000000... count=404\n",
      "  2. syndrome=0000000000... data=0000000000... count=32\n",
      "  3. syndrome=1010000000... data=0000100000... count=29\n",
      "  4. syndrome=0000000001... data=0000000000... count=28\n",
      "  5. syndrome=0000001000... data=0000000000... count=28\n",
      "\n",
      "Logical error rate: 0.000000\n",
      "Expected inner block failure rate: 0.044381\n",
      "Expected logical error rate (approx): 0.000122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/7xjzypk55l37rgqss4ww3jvw0000gn/T/ipykernel_49472/63735331.py:201: DeprecationWarning: `np.math` is a deprecated alias for the standard library `math` module (Deprecated Numpy 1.25). Replace usages of `np.math` with `math`\n",
      "  p_inner_fail = sum(np.math.comb(7, k) * (p**k) * ((1-p)**(7-k)) for k in range(2, 8))\n",
      "/var/folders/vp/7xjzypk55l37rgqss4ww3jvw0000gn/T/ipykernel_49472/63735331.py:204: DeprecationWarning: `np.math` is a deprecated alias for the standard library `math` module (Deprecated Numpy 1.25). Replace usages of `np.math` with `math`\n",
      "  p_outer_fail = sum(np.math.comb(7, k) * (p_inner_fail**k) * ((1-p_inner_fail)**(7-k)) for k in range(4, 8))\n"
     ]
    }
   ],
   "source": [
    "import stim\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "# Hamming (7,4) parity check matrix\n",
    "H_hamming = np.array([\n",
    "    [1,0,1,0,1,0,1],\n",
    "    [0,1,1,0,0,1,1],\n",
    "    [0,0,0,1,1,1,1]\n",
    "], dtype=int)\n",
    "\n",
    "def concatenated_hamming_circuit(p: float = 0.05):\n",
    "    \"\"\"\n",
    "    Concatenated Hamming code circuit (7,4 outer, 7,4 inner) for X-error correction.\n",
    "    \"\"\"\n",
    "    # Outer code length\n",
    "    n_outer = 7\n",
    "    # Inner code length\n",
    "    n_inner = 7\n",
    "    # Total physical qubits\n",
    "    n_data = n_outer * n_inner  # 49 data qubits\n",
    "    # Total stabilizers per outer block\n",
    "    n_stab_per_block = H_hamming.shape[0]  # 3 stabilizers per block\n",
    "    n_stabilizer = n_stab_per_block * n_outer  # 21 total stabilizers\n",
    "    \n",
    "    c = stim.Circuit()\n",
    "    \n",
    "    # Qubit layout: interleave data and measure qubits\n",
    "    # data qubits at even indices, measure qubits at odd\n",
    "    data_qubits = [2*i for i in range(n_data)]\n",
    "    measure_qubits = [2*i + 1 for i in range(n_stabilizer)]\n",
    "    \n",
    "    # Initialize all qubits to |0>\n",
    "    c.append(\"R\", data_qubits + measure_qubits)\n",
    "    \n",
    "    c.append(\"TICK\")\n",
    "    \n",
    "    # Apply X errors on data qubits\n",
    "    for q in data_qubits:\n",
    "        c.append(\"X_ERROR\", [q], p)\n",
    "    \n",
    "    c.append(\"TICK\")\n",
    "    \n",
    "    # Measure stabilizers for each outer code block\n",
    "    measure_index = 0\n",
    "    for outer_idx in range(n_outer):\n",
    "        block_start = outer_idx * n_inner\n",
    "        for row_idx, row in enumerate(H_hamming):\n",
    "            # Find which qubits participate in this stabilizer\n",
    "            participating_data_qubits = [data_qubits[block_start + i] \n",
    "                                         for i, bit in enumerate(row) if bit == 1]\n",
    "            anc = measure_qubits[measure_index]\n",
    "            \n",
    "            # Apply CNOTs from data qubits to ancilla\n",
    "            for q in participating_data_qubits:\n",
    "                c.append(\"CX\", [q, anc])\n",
    "            \n",
    "            measure_index += 1\n",
    "    \n",
    "    c.append(\"TICK\")\n",
    "    \n",
    "    # Measure all ancilla qubits\n",
    "    c.append(\"MR\", measure_qubits)\n",
    "    \n",
    "    # Add detectors for each stabilizer\n",
    "    for i in range(n_stabilizer):\n",
    "        c.append(\"DETECTOR\", [stim.target_rec(-(n_stabilizer) + i)])\n",
    "    \n",
    "    c.append(\"TICK\")\n",
    "    \n",
    "    # Measure all data qubits\n",
    "    c.append(\"M\", data_qubits)\n",
    "    \n",
    "    # Define logical observable - just use first data qubit of first block as logical Z\n",
    "    c.append(\"OBSERVABLE_INCLUDE\", [stim.target_rec(-n_data)], 0)\n",
    "    \n",
    "    return c, n_data, n_stabilizer\n",
    "\n",
    "\n",
    "def simulate_circuit(circuit: stim.Circuit, n_data: int, n_stabilizer: int, num_shots=10000) -> Dict[Tuple[str,str], int]:\n",
    "    \"\"\"\n",
    "    Simulate circuit and extract measurement results.\n",
    "    \"\"\"\n",
    "    sampler = circuit.compile_sampler()\n",
    "    shots = sampler.sample(shots=num_shots)\n",
    "    results = {}\n",
    "    \n",
    "    for shot in shots:\n",
    "        # Measurements come in order: first n_stabilizer ancillas, then n_data data qubits\n",
    "        synd_bits = ''.join(str(int(shot[i])) for i in range(n_stabilizer))\n",
    "        data_bits = ''.join(str(int(shot[n_stabilizer + i])) for i in range(n_data))\n",
    "        key = (data_bits, synd_bits)\n",
    "        results[key] = results.get(key, 0) + 1\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def decode_hamming_block(data_block: list, syndrome_block: list) -> int:\n",
    "    \"\"\"\n",
    "    Decode a single Hamming (7,4) block using syndrome.\n",
    "    \n",
    "    Args:\n",
    "        data_block: list of 7 bits (measurements of data qubits)\n",
    "        syndrome_block: list of 3 bits (syndrome measurements)\n",
    "    \n",
    "    Returns:\n",
    "        Decoded logical bit (majority vote of corrected data)\n",
    "    \"\"\"\n",
    "    corrected = data_block.copy()\n",
    "    syndrome = syndrome_block\n",
    "    \n",
    "    # If syndrome is all zeros, no error detected\n",
    "    if sum(syndrome) == 0:\n",
    "        return 1 if sum(corrected) > 3 else 0\n",
    "    \n",
    "    # Find error location by matching syndrome to H columns\n",
    "    # Each column of H represents the syndrome for an error at that position\n",
    "    for pos in range(7):\n",
    "        column = H_hamming[:, pos]\n",
    "        if np.array_equal(syndrome, column):\n",
    "            # Found the error position - flip it\n",
    "            corrected[pos] ^= 1\n",
    "            break\n",
    "    \n",
    "    # Return majority vote\n",
    "    return 1 if sum(corrected) > 3 else 0\n",
    "\n",
    "\n",
    "def decode_hamming_concatenated(meas: Tuple[str, str]) -> int:\n",
    "    \"\"\"\n",
    "    Decode concatenated Hamming code:\n",
    "    - Decode each inner Hamming (7,4) block using its syndrome\n",
    "    - Perform majority vote on the 7 outer logical qubits\n",
    "    \"\"\"\n",
    "    data_bits, synd_bits = meas\n",
    "    n_outer = 7\n",
    "    n_inner = 7\n",
    "    n_stab_per_block = 3\n",
    "    \n",
    "    data = [int(b) for b in data_bits]\n",
    "    synd = [int(b) for b in synd_bits]\n",
    "    \n",
    "    # Decode each of the 7 inner blocks\n",
    "    outer_logical_bits = []\n",
    "    for outer_idx in range(n_outer):\n",
    "        # Extract data and syndrome for this block\n",
    "        data_start = outer_idx * n_inner\n",
    "        data_end = data_start + n_inner\n",
    "        data_block = data[data_start:data_end]\n",
    "        \n",
    "        synd_start = outer_idx * n_stab_per_block\n",
    "        synd_end = synd_start + n_stab_per_block\n",
    "        syndrome_block = synd[synd_start:synd_end]\n",
    "        \n",
    "        # Decode this inner block\n",
    "        logical_bit = decode_hamming_block(data_block, syndrome_block)\n",
    "        outer_logical_bits.append(logical_bit)\n",
    "    \n",
    "    # Now decode the outer code using majority vote\n",
    "    # (The outer code is also a Hamming code, but we're just using majority vote)\n",
    "    return 1 if sum(outer_logical_bits) > n_outer // 2 else 0\n",
    "\n",
    "\n",
    "def logical_error_rate(results: Dict[Tuple[str,str], int], logical_prepared=0) -> float:\n",
    "    \"\"\"\n",
    "    Compute logical error rate.\n",
    "    \"\"\"\n",
    "    errors = 0\n",
    "    total = 0\n",
    "    for (data_bits, synd_bits), count in results.items():\n",
    "        decoded = decode_hamming_concatenated((data_bits, synd_bits))\n",
    "        if decoded != logical_prepared:\n",
    "            errors += count\n",
    "        total += count\n",
    "    return errors / total\n",
    "\n",
    "\n",
    "# Test the code\n",
    "print(\"Building concatenated Hamming circuit...\")\n",
    "circuit, n_data, n_stab = concatenated_hamming_circuit(p=0.05)\n",
    "print(f\"Circuit has {n_data} data qubits and {n_stab} stabilizers\")\n",
    "print(f\"\\nCircuit preview (first 20 lines):\")\n",
    "print('\\n'.join(str(circuit).split('\\n')[:20]))\n",
    "\n",
    "print(\"\\nRunning simulation...\")\n",
    "results = simulate_circuit(circuit, n_data, n_stab, num_shots=5000)\n",
    "\n",
    "print(f\"\\nNumber of unique measurement outcomes: {len(results)}\")\n",
    "print(f\"Most common outcomes:\")\n",
    "for i, (key, count) in enumerate(sorted(results.items(), key=lambda x: -x[1])[:5]):\n",
    "    data, synd = key\n",
    "    print(f\"  {i+1}. syndrome={synd[:10]}... data={data[:10]}... count={count}\")\n",
    "\n",
    "p_L = logical_error_rate(results, logical_prepared=0)\n",
    "print(f\"\\nLogical error rate: {p_L:.6f}\")\n",
    "\n",
    "# Rough analytical estimate\n",
    "# Inner code can correct 1 error per block (distance 3)\n",
    "# Probability of >1 error in a block of 7 with p=0.05:\n",
    "p = 0.05\n",
    "p_inner_fail = sum(np.math.comb(7, k) * (p**k) * ((1-p)**(7-k)) for k in range(2, 8))\n",
    "print(f\"Expected inner block failure rate: {p_inner_fail:.6f}\")\n",
    "# Outer code needs >3 inner failures\n",
    "p_outer_fail = sum(np.math.comb(7, k) * (p_inner_fail**k) * ((1-p_inner_fail)**(7-k)) for k in range(4, 8))\n",
    "print(f\"Expected logical error rate (approx): {p_outer_fail:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying with 100,000 simulations instead of 5,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building concatenated Hamming circuit...\n",
      "Circuit has 49 data qubits and 21 stabilizers\n",
      "\n",
      "Running simulation with 100,000 shots...\n",
      "\n",
      "Number of unique measurement outcomes: 36415\n",
      "Most common outcomes:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'errors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 210\u001b[0m\n\u001b[1;32m    208\u001b[0m     num_errors \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(\u001b[39mint\u001b[39m(b) \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m data)\n\u001b[1;32m    209\u001b[0m     num_syndromes \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(\u001b[39mint\u001b[39m(b) \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m synd)\n\u001b[0;32m--> 210\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m  \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m. #\u001b[39m\u001b[39m{\u001b[39;00merrors\u001b[39m}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{\u001b[39;00mnum_errors\u001b[39m}\u001b[39;00m\u001b[39m, #synd=\u001b[39m\u001b[39m{\u001b[39;00mnum_syndromes\u001b[39m}\u001b[39;00m\u001b[39m, count=\u001b[39m\u001b[39m{\u001b[39;00mcount\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    212\u001b[0m p_L \u001b[39m=\u001b[39m logical_error_rate(results, logical_prepared\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    213\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m60\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'errors' is not defined"
     ]
    }
   ],
   "source": [
    "import stim\n",
    "import numpy as np\n",
    "import math\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "# Hamming (7,4) parity check matrix\n",
    "H_hamming = np.array([\n",
    "    [1,0,1,0,1,0,1],\n",
    "    [0,1,1,0,0,1,1],\n",
    "    [0,0,0,1,1,1,1]\n",
    "], dtype=int)\n",
    "\n",
    "def concatenated_hamming_circuit(p: float = 0.05):\n",
    "    \"\"\"\n",
    "    Concatenated Hamming code circuit (7,4 outer, 7,4 inner) for X-error correction.\n",
    "    \"\"\"\n",
    "    n_outer = 7\n",
    "    n_inner = 7\n",
    "    n_data = n_outer * n_inner  # 49 data qubits\n",
    "    n_stab_per_block = H_hamming.shape[0]  # 3 stabilizers per block\n",
    "    n_stabilizer = n_stab_per_block * n_outer  # 21 total stabilizers\n",
    "    \n",
    "    c = stim.Circuit()\n",
    "    \n",
    "    # Qubit layout: interleave data and measure qubits\n",
    "    data_qubits = [2*i for i in range(n_data)]\n",
    "    measure_qubits = [2*i + 1 for i in range(n_stabilizer)]\n",
    "    \n",
    "    # Initialize all qubits to |0>\n",
    "    c.append(\"R\", data_qubits + measure_qubits)\n",
    "    \n",
    "    c.append(\"TICK\")\n",
    "    \n",
    "    # Apply X errors on data qubits\n",
    "    for q in data_qubits:\n",
    "        c.append(\"X_ERROR\", [q], p)\n",
    "    \n",
    "    c.append(\"TICK\")\n",
    "    \n",
    "    # Measure stabilizers for each outer code block\n",
    "    measure_index = 0\n",
    "    for outer_idx in range(n_outer):\n",
    "        block_start = outer_idx * n_inner\n",
    "        for row_idx, row in enumerate(H_hamming):\n",
    "            # Find which qubits participate in this stabilizer\n",
    "            participating_data_qubits = [data_qubits[block_start + i] \n",
    "                                         for i, bit in enumerate(row) if bit == 1]\n",
    "            anc = measure_qubits[measure_index]\n",
    "            \n",
    "            # Apply CNOTs from data qubits to ancilla\n",
    "            for q in participating_data_qubits:\n",
    "                c.append(\"CX\", [q, anc])\n",
    "            \n",
    "            measure_index += 1\n",
    "    \n",
    "    c.append(\"TICK\")\n",
    "    \n",
    "    # Measure all ancilla qubits\n",
    "    c.append(\"MR\", measure_qubits)\n",
    "    \n",
    "    # Add detectors for each stabilizer\n",
    "    for i in range(n_stabilizer):\n",
    "        c.append(\"DETECTOR\", [stim.target_rec(-(n_stabilizer) + i)])\n",
    "    \n",
    "    c.append(\"TICK\")\n",
    "    \n",
    "    # Measure all data qubits\n",
    "    c.append(\"M\", data_qubits)\n",
    "    \n",
    "    # Define logical observable - just use first data qubit of first block as logical Z\n",
    "    c.append(\"OBSERVABLE_INCLUDE\", [stim.target_rec(-n_data)], 0)\n",
    "    \n",
    "    return c, n_data, n_stabilizer\n",
    "\n",
    "\n",
    "def simulate_circuit(circuit: stim.Circuit, n_data: int, n_stabilizer: int, num_shots=10000) -> Dict[Tuple[str,str], int]:\n",
    "    \"\"\"\n",
    "    Simulate circuit and extract measurement results.\n",
    "    \"\"\"\n",
    "    sampler = circuit.compile_sampler()\n",
    "    shots = sampler.sample(shots=num_shots)\n",
    "    results = {}\n",
    "    \n",
    "    for shot in shots:\n",
    "        # Measurements come in order: first n_stabilizer ancillas, then n_data data qubits\n",
    "        synd_bits = ''.join(str(int(shot[i])) for i in range(n_stabilizer))\n",
    "        data_bits = ''.join(str(int(shot[n_stabilizer + i])) for i in range(n_data))\n",
    "        key = (data_bits, synd_bits)\n",
    "        results[key] = results.get(key, 0) + 1\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def decode_hamming_block(data_block: list, syndrome_block: list) -> int:\n",
    "    \"\"\"\n",
    "    Decode a single Hamming (7,4) block using syndrome.\n",
    "    \n",
    "    Args:\n",
    "        data_block: list of 7 bits (measurements of data qubits)\n",
    "        syndrome_block: list of 3 bits (syndrome measurements)\n",
    "    \n",
    "    Returns:\n",
    "        Decoded logical bit (majority vote of corrected data)\n",
    "    \"\"\"\n",
    "    corrected = data_block.copy()\n",
    "    syndrome = syndrome_block\n",
    "    \n",
    "    # If syndrome is all zeros, no error detected\n",
    "    if sum(syndrome) == 0:\n",
    "        return 1 if sum(corrected) > 3 else 0\n",
    "    \n",
    "    # Find error location by matching syndrome to H columns\n",
    "    # Each column of H represents the syndrome for an error at that position\n",
    "    for pos in range(7):\n",
    "        column = H_hamming[:, pos]\n",
    "        if np.array_equal(syndrome, column):\n",
    "            # Found the error position - flip it\n",
    "            corrected[pos] ^= 1\n",
    "            break\n",
    "    \n",
    "    # Return majority vote\n",
    "    return 1 if sum(corrected) > 3 else 0\n",
    "\n",
    "\n",
    "def decode_hamming_concatenated(meas: Tuple[str, str], verbose=False) -> int:\n",
    "    \"\"\"\n",
    "    Decode concatenated Hamming code:\n",
    "    - Decode each inner Hamming (7,4) block using its syndrome\n",
    "    - Perform majority vote on the 7 outer logical qubits\n",
    "    \"\"\"\n",
    "    data_bits, synd_bits = meas\n",
    "    n_outer = 7\n",
    "    n_inner = 7\n",
    "    n_stab_per_block = 3\n",
    "    \n",
    "    data = [int(b) for b in data_bits]\n",
    "    synd = [int(b) for b in synd_bits]\n",
    "    \n",
    "    # Decode each of the 7 inner blocks\n",
    "    outer_logical_bits = []\n",
    "    for outer_idx in range(n_outer):\n",
    "        # Extract data and syndrome for this block\n",
    "        data_start = outer_idx * n_inner\n",
    "        data_end = data_start + n_inner\n",
    "        data_block = data[data_start:data_end]\n",
    "        \n",
    "        synd_start = outer_idx * n_stab_per_block\n",
    "        synd_end = synd_start + n_stab_per_block\n",
    "        syndrome_block = synd[synd_start:synd_end]\n",
    "        \n",
    "        # Decode this inner block\n",
    "        logical_bit = decode_hamming_block(data_block, syndrome_block)\n",
    "        outer_logical_bits.append(logical_bit)\n",
    "        \n",
    "        if verbose and outer_idx < 2:\n",
    "            print(f\"  Block {outer_idx}: data={data_block}, synd={syndrome_block}, logical={logical_bit}\")\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"  Outer logical bits: {outer_logical_bits}\")\n",
    "    \n",
    "    # Now decode the outer code using majority vote\n",
    "    result = 1 if sum(outer_logical_bits) > n_outer // 2 else 0\n",
    "    if verbose:\n",
    "        print(f\"  Final result: {result}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def logical_error_rate(results: Dict[Tuple[str,str], int], logical_prepared=0, verbose=False) -> float:\n",
    "    \"\"\"\n",
    "    Compute logical error rate.\n",
    "    \"\"\"\n",
    "    errors = 0\n",
    "    total = 0\n",
    "    error_cases = []\n",
    "    \n",
    "    for (data_bits, synd_bits), count in results.items():\n",
    "        decoded = decode_hamming_concatenated((data_bits, synd_bits))\n",
    "        if decoded != logical_prepared:\n",
    "            errors += count\n",
    "            if len(error_cases) < 3:  # Save first few error cases\n",
    "                error_cases.append((data_bits, synd_bits, count))\n",
    "        total += count\n",
    "    \n",
    "    if verbose and error_cases:\n",
    "        print(f\"\\nExample error cases:\")\n",
    "        for i, (data, synd, count) in enumerate(error_cases):\n",
    "            print(f\"\\nError case {i+1} (occurred {count} times):\")\n",
    "            print(f\"Data: {data[:20]}...\")\n",
    "            print(f\"Synd: {synd}\")\n",
    "            decode_hamming_concatenated((data, synd), verbose=True)\n",
    "    \n",
    "    return errors / total\n",
    "\n",
    "\n",
    "# Test with more shots\n",
    "print(\"Building concatenated Hamming circuit...\")\n",
    "p = 0.05\n",
    "circuit, n_data, n_stab = concatenated_hamming_circuit(p=p)\n",
    "print(f\"Circuit has {n_data} data qubits and {n_stab} stabilizers\")\n",
    "\n",
    "print(\"\\nRunning simulation with 100,000 shots...\")\n",
    "results = simulate_circuit(circuit, n_data, n_stab, num_shots=100_000)\n",
    "\n",
    "print(f\"\\nNumber of unique measurement outcomes: {len(results)}\")\n",
    "print(f\"Most common outcomes:\")\n",
    "for i, (key, count) in enumerate(sorted(results.items(), key=lambda x: -x[1])[:5]):\n",
    "    data, synd = key\n",
    "    num_errors = sum(int(b) for b in data)\n",
    "    num_syndromes = sum(int(b) for b in synd)\n",
    "    print(f\"  {i+1}. #errors={num_errors}, #synd={num_syndromes}, count={count}\")\n",
    "\n",
    "p_L = logical_error_rate(results, logical_prepared=0, verbose=True)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Logical error rate: {p_L:.6f}\")\n",
    "\n",
    "# Analytical estimate\n",
    "p_inner_fail = sum(math.comb(7, k) * (p**k) * ((1-p)**(7-k)) for k in range(2, 8))\n",
    "print(f\"Expected inner block failure rate: {p_inner_fail:.6f}\")\n",
    "p_outer_fail = sum(math.comb(7, k) * (p_inner_fail**k) * ((1-p_inner_fail)**(7-k)) for k in range(4, 8))\n",
    "print(f\"Expected logical error rate (approx): {p_outer_fail:.6f}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Compare to repetition code\n",
    "print(f\"\\nFor comparison:\")\n",
    "print(f\"Physical error rate: {p:.6f}\")\n",
    "print(f\"Repetition code (n=49): ~{sum(math.comb(49, k) * (p**k) * ((1-p)**(49-k)) for k in range(25, 50)):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
